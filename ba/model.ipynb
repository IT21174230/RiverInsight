{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('master2.csv')\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data = data.sort_values(by='date')\n",
    "\n",
    "# Encode date-related features as sine and cosine transformations\n",
    "data['month'] = data['date'].dt.month\n",
    "data['day_of_year'] = data['date'].dt.dayofyear\n",
    "data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "data['day_sin'] = np.sin(2 * np.pi * data['day_of_year'] / 365)\n",
    "data['day_cos'] = np.cos(2 * np.pi * data['day_of_year'] / 365)\n",
    "\n",
    "# Add lag features\n",
    "data['lag1'] = data['water_area_km2'].shift(1)\n",
    "data['lag3'] = data['water_area_km2'].shift(3)\n",
    "data['lag7'] = data['water_area_km2'].shift(7)\n",
    "data['lag14'] = data['water_area_km2'].shift(14)\n",
    "\n",
    "# Feature engineering\n",
    "data['rolling_avg_7'] = data['water_area_km2'].rolling(window=7).mean()\n",
    "data['rolling_median_7'] = data['water_area_km2'].rolling(window=7).median()\n",
    "data['rolling_std_7'] = data['water_area_km2'].rolling(window=7).std()\n",
    "data['expanding_mean'] = data['water_area_km2'].expanding().mean()\n",
    "data['cumulative_rainfall'] = data['Rainfall'].cumsum()\n",
    "data['rainfall_ndwi_interaction'] = data['Rainfall'] * data['mean_ndwi']\n",
    "data['extreme_rainfall'] = (data['Rainfall'] > data['Rainfall'].quantile(0.95)).astype(int)\n",
    "\n",
    "# Calculate monthly aggregates\n",
    "data['month_year'] = data['date'].dt.to_period('M')\n",
    "monthly_aggregates = data.groupby('month_year')[['water_area_km2']].agg(['mean', 'max']).reset_index()\n",
    "monthly_aggregates.columns = ['month_year', 'monthly_mean', 'monthly_max']\n",
    "data = pd.merge(data, monthly_aggregates, how='left', on='month_year')\n",
    "\n",
    "# Handle missing values\n",
    "data = data.fillna(method='ffill')\n",
    "\n",
    "# Train-test split (80/20 split)\n",
    "train_data = data.iloc[:int(len(data) * 0.7)].dropna()\n",
    "test_data = data.iloc[int(len(data) * 0.7):].dropna()\n",
    "\n",
    "# Prepare data for Prophet\n",
    "prophet_train = train_data.rename(columns={'date': 'ds', 'water_area_km2': 'y'})\n",
    "prophet_test = test_data.rename(columns={'date': 'ds', 'water_area_km2': 'y'})\n",
    "\n",
    "# Define additional regressors\n",
    "additional_regressors = [\n",
    "    'Average_Temperature', 'Rainfall', 'lag1', 'lag3', 'lag7', 'lag14',\n",
    "    'rolling_avg_7', 'rolling_median_7', 'rolling_std_7', 'expanding_mean',\n",
    "    'cumulative_rainfall', 'rainfall_ndwi_interaction', 'extreme_rainfall',\n",
    "    'month_sin', 'month_cos', 'day_sin', 'day_cos',\n",
    "    'monthly_mean', 'monthly_max','Average_Humidity','Max_Humidity','Average_Wind_Speed','Max_Wind_Speed','Max_Temperature'\n",
    "]\n",
    "\n",
    "for regressor in additional_regressors:\n",
    "    if regressor in train_data.columns:\n",
    "        prophet_train[regressor] = train_data[regressor]\n",
    "        prophet_test[regressor] = test_data[regressor]\n",
    "\n",
    "# Hyperparameter tuning (cross-validation)\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.01, 0.1, 0.5, 1.0],\n",
    "    'seasonality_prior_scale': [0.1, 1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_score = float('inf')\n",
    "\n",
    "# Cross-validation to check for overfitting\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "for changepoint_prior_scale, seasonality_prior_scale in product(param_grid['changepoint_prior_scale'], param_grid['seasonality_prior_scale']):\n",
    "    cv_scores = []\n",
    "    \n",
    "    # Perform cross-validation with independent Prophet models in each fold\n",
    "    for train_idx, val_idx in tscv.split(prophet_train):\n",
    "        train_cv, val_cv = prophet_train.iloc[train_idx], prophet_train.iloc[val_idx]\n",
    "        \n",
    "        model = Prophet(\n",
    "            changepoint_prior_scale=changepoint_prior_scale,\n",
    "            seasonality_prior_scale=seasonality_prior_scale,\n",
    "            daily_seasonality=True\n",
    "        )\n",
    "\n",
    "        for regressor in additional_regressors:\n",
    "            if regressor in prophet_train.columns:\n",
    "                model.add_regressor(regressor)\n",
    "        \n",
    "        model.fit(train_cv)\n",
    "        forecast = model.predict(val_cv)\n",
    "        mae = mean_absolute_error(val_cv['y'], forecast['yhat'])\n",
    "        cv_scores.append(mae)\n",
    "\n",
    "    avg_cv_score = np.mean(cv_scores)\n",
    "\n",
    "    if avg_cv_score < best_score:\n",
    "        best_score = avg_cv_score\n",
    "        best_params = (changepoint_prior_scale, seasonality_prior_scale)\n",
    "\n",
    "# Train Prophet model with optimal hyperparameters\n",
    "optimal_changepoint_prior_scale, optimal_seasonality_prior_scale = best_params\n",
    "\n",
    "prophet_model = Prophet(\n",
    "    changepoint_prior_scale=optimal_changepoint_prior_scale,\n",
    "    seasonality_prior_scale=optimal_seasonality_prior_scale,\n",
    "    daily_seasonality=True\n",
    ")\n",
    "\n",
    "for regressor in additional_regressors:\n",
    "    if regressor in prophet_train.columns:\n",
    "        prophet_model.add_regressor(regressor)\n",
    "\n",
    "prophet_model.fit(prophet_train)\n",
    "\n",
    "# Make predictions\n",
    "forecast_train = prophet_model.predict(prophet_train)\n",
    "forecast_test = prophet_model.predict(prophet_test)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(y_true, y_pred, data_split):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{data_split} - MAE: {mae:.2f}, MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n",
    "evaluate_model(prophet_train['y'], forecast_train['yhat'], 'Train')\n",
    "evaluate_model(prophet_test['y'], forecast_test['yhat'], 'Test')\n",
    "\n",
    "print(f\"Optimal Hyperparameters: changepoint_prior_scale={optimal_changepoint_prior_scale}, seasonality_prior_scale={optimal_seasonality_prior_scale}\")\n",
    "\n",
    "# Save Prophet predictions\n",
    "forecast_test[['ds', 'yhat']].to_csv('prophet_predictions_optimized.csv', index=False)\n",
    "print(\"Prophet predictions saved to 'prophet_predictions_optimized.csv'.\")\n",
    "\n",
    "# Prophet Visualization: Actual vs. Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(prophet_test['ds'], prophet_test['y'], label='Actual', color='blue')\n",
    "plt.plot(forecast_test['ds'], forecast_test['yhat'], label='Predicted', color='red')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Water Area (km²)')\n",
    "plt.title('Prophet: Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Prophet trend components\n",
    "prophet_model.plot_components(forecast_test)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
