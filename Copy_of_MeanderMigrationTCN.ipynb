{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdk8AI9kaCn2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scipy.signal import medfilt\n",
        "from keras.regularizers import l2\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import KFold\n",
        "import joblib\n",
        "\n",
        "# import innvestigate\n",
        "# import innvestigate.utils as iutils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDKNDP3EqzKc"
      },
      "outputs": [],
      "source": [
        "pip install innvestigate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "id": "UbnmTxCqceuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y scikit-learn\n",
        "!pip install scikit-learn==1.5.2"
      ],
      "metadata": {
        "id": "Sft703CPc2oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rxBCtleaI2A"
      },
      "outputs": [],
      "source": [
        "dataset='/content/MeanderingInterploatedUpdated.csv'\n",
        "df=pd.read_csv(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5DmO8yOaV_X"
      },
      "outputs": [],
      "source": [
        "df['year'] = df['name'].apply(lambda x: int(x.split('-')[0]))\n",
        "df['quarter'] = df['name'].apply(lambda x: int(x.split('-')[1]))\n",
        "\n",
        "# df_encoded = pd.get_dummies(df, columns=['quarter'], drop_first=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpxZeeehd1FD"
      },
      "outputs": [],
      "source": [
        "targets = ['c1_dist', 'c2_dist', 'c3_dist', 'c4_dist','c7_dist','c8_dist']\n",
        "ts= df[targets]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in ts.columns:\n",
        "  ts[i]=medfilt(ts[i], kernel_size=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVljYbxmyzgH",
        "outputId": "4a70cff6-bb1b-46cd-ed6a-e4954363f7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-93-738e01451d00>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ts[i]=medfilt(ts[i], kernel_size=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRPqnDR6Wdbm"
      },
      "outputs": [],
      "source": [
        "scaler_ts = StandardScaler()\n",
        "ts_normalized=scaler_ts.fit_transform(ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qPPfjQulmka"
      },
      "outputs": [],
      "source": [
        "def add_time_features(df, scaler):\n",
        "    # Cyclical encoding for quarter\n",
        "    df['quarter_sin'] = np.sin(2 * np.pi * df['quarter'] / 4)\n",
        "    df['quarter_cos'] = np.cos(2 * np.pi * df['quarter'] / 4)\n",
        "\n",
        "    # # Cyclical encoding for year (you can normalize the year value if needed)\n",
        "    # df['year_sin'] = np.sin(2 * np.pi * (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min()))\n",
        "    # df['year_cos'] = np.cos(2 * np.pi * (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min()))\n",
        "\n",
        "    df['year_scaled'] = scaler.fit_transform(df[['year']])  # Use double brackets to make it 2D    return df\n",
        "\n",
        "    return df\n",
        "\n",
        "scaler_year=StandardScaler()\n",
        "df = add_time_features(df, scaler_year)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "rF2uebIEl1Ou",
        "outputId": "38c897d3-5c58-441b-8f98-017b62bdcfb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0    name    c1_dist    c2_dist      c3_dist      c4_dist  \\\n",
              "0           0  1988-1  80.622577   2.236068  1118.456079  1087.443332   \n",
              "1           1  1988-2  89.201242   8.732515  1112.007378  1089.762294   \n",
              "2           2  1988-3  90.426766  10.770330  1091.650127  1090.093574   \n",
              "3           3  1988-4  75.000000   8.062258   892.453360   968.810095   \n",
              "4           4  1989-1  75.485233   8.156297   852.133189   926.992124   \n",
              "\n",
              "       c5_dist      c6_dist      c7_dist      c8_dist  year  quarter  \\\n",
              "0  2572.616567  2748.070232  2197.682643  2400.496824  1988        1   \n",
              "1  2571.456646  2747.082249  2190.347995  2392.594177  1988        2   \n",
              "2  2567.532084  2743.753998  2166.673026  2367.186516  1988        3   \n",
              "3  2475.422590  2671.696465  1879.447259  2071.386251  1988        4   \n",
              "4  2424.462205  2622.730393  1848.250870  2040.697558  1989        1   \n",
              "\n",
              "    quarter_sin   quarter_cos  year_scaled  \n",
              "0  1.000000e+00  6.123234e-17    -1.678160  \n",
              "1  1.224647e-16 -1.000000e+00    -1.678160  \n",
              "2 -1.000000e+00 -1.836970e-16    -1.678160  \n",
              "3 -2.449294e-16  1.000000e+00    -1.678160  \n",
              "4  1.000000e+00  6.123234e-17    -1.584681  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aaecead0-6da8-4570-a244-d8d72445a97c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>c1_dist</th>\n",
              "      <th>c2_dist</th>\n",
              "      <th>c3_dist</th>\n",
              "      <th>c4_dist</th>\n",
              "      <th>c5_dist</th>\n",
              "      <th>c6_dist</th>\n",
              "      <th>c7_dist</th>\n",
              "      <th>c8_dist</th>\n",
              "      <th>year</th>\n",
              "      <th>quarter</th>\n",
              "      <th>quarter_sin</th>\n",
              "      <th>quarter_cos</th>\n",
              "      <th>year_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1988-1</td>\n",
              "      <td>80.622577</td>\n",
              "      <td>2.236068</td>\n",
              "      <td>1118.456079</td>\n",
              "      <td>1087.443332</td>\n",
              "      <td>2572.616567</td>\n",
              "      <td>2748.070232</td>\n",
              "      <td>2197.682643</td>\n",
              "      <td>2400.496824</td>\n",
              "      <td>1988</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>6.123234e-17</td>\n",
              "      <td>-1.678160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1988-2</td>\n",
              "      <td>89.201242</td>\n",
              "      <td>8.732515</td>\n",
              "      <td>1112.007378</td>\n",
              "      <td>1089.762294</td>\n",
              "      <td>2571.456646</td>\n",
              "      <td>2747.082249</td>\n",
              "      <td>2190.347995</td>\n",
              "      <td>2392.594177</td>\n",
              "      <td>1988</td>\n",
              "      <td>2</td>\n",
              "      <td>1.224647e-16</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.678160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1988-3</td>\n",
              "      <td>90.426766</td>\n",
              "      <td>10.770330</td>\n",
              "      <td>1091.650127</td>\n",
              "      <td>1090.093574</td>\n",
              "      <td>2567.532084</td>\n",
              "      <td>2743.753998</td>\n",
              "      <td>2166.673026</td>\n",
              "      <td>2367.186516</td>\n",
              "      <td>1988</td>\n",
              "      <td>3</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.836970e-16</td>\n",
              "      <td>-1.678160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1988-4</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>8.062258</td>\n",
              "      <td>892.453360</td>\n",
              "      <td>968.810095</td>\n",
              "      <td>2475.422590</td>\n",
              "      <td>2671.696465</td>\n",
              "      <td>1879.447259</td>\n",
              "      <td>2071.386251</td>\n",
              "      <td>1988</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.449294e-16</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>-1.678160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1989-1</td>\n",
              "      <td>75.485233</td>\n",
              "      <td>8.156297</td>\n",
              "      <td>852.133189</td>\n",
              "      <td>926.992124</td>\n",
              "      <td>2424.462205</td>\n",
              "      <td>2622.730393</td>\n",
              "      <td>1848.250870</td>\n",
              "      <td>2040.697558</td>\n",
              "      <td>1989</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>6.123234e-17</td>\n",
              "      <td>-1.584681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aaecead0-6da8-4570-a244-d8d72445a97c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aaecead0-6da8-4570-a244-d8d72445a97c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aaecead0-6da8-4570-a244-d8d72445a97c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dfaca700-6b78-4906-b9c9-c6dd2cd1fc15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfaca700-6b78-4906-b9c9-c6dd2cd1fc15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dfaca700-6b78-4906-b9c9-c6dd2cd1fc15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 147,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 0,\n        \"max\": 146,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          125,\n          51,\n          138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"2019-3\",\n          \"2000-4\",\n          \"2022-4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c1_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.041666748928204,\n        \"min\": 75.0,\n        \"max\": 246.9696338,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          133.16725112693078,\n          106.2274253234832,\n          146.7276388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c2_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.89851839690145,\n        \"min\": 2.236067977,\n        \"max\": 169.5788902,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          66.30023059227025,\n          20.48203476344647,\n          83.77350416\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c3_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126.69426191339228,\n        \"min\": 612.2091146,\n        \"max\": 1118.456079,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          827.4329088000002,\n          1088.4221594564804,\n          1035.791968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c4_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 109.60992342042523,\n        \"min\": 599.0300493,\n        \"max\": 1090.093574,\n        \"num_unique_values\": 146,\n        \"samples\": [\n          1066.5913065382197,\n          1045.8805964044548,\n          995.0894094983112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c5_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146.55752626687052,\n        \"min\": 2030.622072,\n        \"max\": 2572.616567,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          2358.2916885,\n          2559.747234395644,\n          2458.158864\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c6_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 152.92863687750676,\n        \"min\": 2170.889449,\n        \"max\": 2748.070232,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          2544.042355,\n          2737.7665292726238,\n          2522.134017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c7_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111.44560740530886,\n        \"min\": 1685.584172,\n        \"max\": 2197.682643,\n        \"num_unique_values\": 142,\n        \"samples\": [\n          2050.475311,\n          1758.820146256,\n          1998.2874670389056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c8_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111.25690201641143,\n        \"min\": 1889.040497,\n        \"max\": 2400.496824,\n        \"num_unique_values\": 142,\n        \"samples\": [\n          2235.497484,\n          1954.901562144,\n          2173.8383321145348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1988,\n        \"max\": 2024,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          2005,\n          2001,\n          1992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter_sin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7119335046677415,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.2246467991473532e-16,\n          -2.4492935982947064e-16,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7070738334996866,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -1.0,\n          1.0,\n          6.123233995736766e-17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0034188133917432,\n        \"min\": -1.6781597597140177,\n        \"max\": 1.6870624640095806,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          -0.08902704295565175,\n          -0.4629406233693849,\n          -1.3042461793002844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMuRGpaiSGFY"
      },
      "outputs": [],
      "source": [
        "for col in ts.columns:\n",
        "    series = df[col]\n",
        "\n",
        "    # Additive decomposition\n",
        "    additive_result = seasonal_decompose(series, model=\"additive\", period=7)\n",
        "    # Multiplicative decomposition\n",
        "    multiplicative_result = seasonal_decompose(series, model=\"multiplicative\", period=7)\n",
        "\n",
        "    # Plot additive decomposition\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.suptitle(f\"Additive Decomposition for {col}\", fontsize=16)\n",
        "    plt.subplot(411)\n",
        "    plt.plot(series, label=\"Observed\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.subplot(412)\n",
        "    plt.plot(additive_result.trend, label=\"Trend\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.subplot(413)\n",
        "    plt.plot(additive_result.seasonal, label=\"Seasonal\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.subplot(414)\n",
        "    plt.plot(additive_result.resid, label=\"Residual\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "\n",
        "    # Plot multiplicative decomposition\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.suptitle(f\"Multiplicative Decomposition for {col}\", fontsize=16)\n",
        "    plt.subplot(411)\n",
        "    plt.plot(series, label=\"Observed\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.subplot(412)\n",
        "    plt.plot(multiplicative_result.trend, label=\"Trend\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.subplot(413)\n",
        "    plt.plot(multiplicative_result.seasonal, label=\"Seasonal\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.subplot(414)\n",
        "    plt.plot(multiplicative_result.resid, label=\"Residual\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ItIT36ROsnn"
      },
      "outputs": [],
      "source": [
        "# redundant_features= pd.concat([ts, ts_ema], axis=1)\n",
        "# redundant_features_normalized=scaler.fit_transform(redundant_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TApBf5OPTen3",
        "outputId": "f16e4c68-03ea-44ae-da22-50386f5a5788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Component 1: 61.97% explained variance\n",
            "Component 2: 32.01% explained variance\n",
            "Component 3: 5.34% explained variance\n",
            "Component 4: 0.56% explained variance\n",
            "Component 5: 0.11% explained variance\n",
            "Component 6: 0.01% explained variance\n",
            "Cumulative explained variance: [0.61974363 0.93986644 0.99325438 0.99887277 0.99992648 1.        ]\n"
          ]
        }
      ],
      "source": [
        "pca = PCA()\n",
        "pca_components = pca.fit_transform(ts_normalized)\n",
        "\n",
        "# Explained variance ratio for each component\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Cumulative explained variance\n",
        "cumulative_variance = explained_variance.cumsum()\n",
        "\n",
        "# Print explained variance for each component\n",
        "for i, var in enumerate(explained_variance):\n",
        "    print(f\"Component {i+1}: {var:.2%} explained variance\")\n",
        "print(f\"Cumulative explained variance: {cumulative_variance}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtOutszwUEN9",
        "outputId": "7db69b80-4448-4c3f-c89b-844046acb377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of components to retain: 3\n"
          ]
        }
      ],
      "source": [
        "n_components = (cumulative_variance < 0.98).sum() + 1\n",
        "print(f\"Number of components to retain: {n_components}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmPQKumrUSon"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=n_components)\n",
        "reduced_features = pca.fit_transform(ts_normalized)\n",
        "\n",
        "reduced_features_df = pd.DataFrame(reduced_features, columns=[f\"PC{i+1}\" for i in range(n_components)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ADAhrIPec49"
      },
      "outputs": [],
      "source": [
        "def create_windows(features, output, time_features, input_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(features) - input_steps):\n",
        "        # Use the features of the current window, including cyclical time features\n",
        "        X.append(np.concatenate([features[i:i + input_steps], time_features[i:i + input_steps]], axis=1))\n",
        "\n",
        "        # Output only the features of the next step (output at i + input_steps)\n",
        "        y.append(output[i + input_steps])\n",
        "\n",
        "        if i == 0:  # Debugging information for the first window\n",
        "            print(f\"Time features (1st window):\\n{time_features[i:i + input_steps]}\")\n",
        "            print(f\"Input features (1st window):\\n{X[0]}\")\n",
        "            print(f\"Output features (1st step after input window):\\n{y[0]}\")\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# Assuming `data` is your time series data, and `time_features` is the DataFrame containing the cyclical time features\n",
        "input_steps = 4\n",
        "output_steps = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbZZn4lJmvFq",
        "outputId": "1e2b144d-888e-406f-da66-13c2c4bd9460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time_feat:(147, 3)\n",
            "Time features (1st window):\n",
            "[[ 1.40942772e+00  9.65384094e-03 -1.67815976e+00]\n",
            " [ 1.90920617e-16 -1.40946078e+00 -1.67815976e+00]\n",
            " [-1.40942772e+00  9.65384094e-03 -1.67815976e+00]\n",
            " [-3.26894726e-16  1.42876846e+00 -1.67815976e+00]]\n",
            "Input features (1st window):\n",
            "[[ 2.65728213e+00 -2.27517620e+00  1.11816363e+00  1.40942772e+00\n",
            "   9.65384094e-03 -1.67815976e+00]\n",
            " [ 2.73707612e+00 -1.91175990e+00  1.13536030e+00  1.90920617e-16\n",
            "  -1.40946078e+00 -1.67815976e+00]\n",
            " [ 2.42255980e+00 -1.84368953e+00  9.82191848e-01 -1.40942772e+00\n",
            "   9.65384094e-03 -1.67815976e+00]\n",
            " [-1.80028181e+00 -1.34339584e+00 -3.67389752e-01 -3.26894726e-16\n",
            "   1.42876846e+00 -1.67815976e+00]]\n",
            "Output features (1st step after input window):\n",
            "[-1.42345209 -0.93232542 -1.26601734 -0.78307871 -1.20903361 -1.12829837]\n"
          ]
        }
      ],
      "source": [
        "time_features = df[['quarter_sin', 'quarter_cos', 'year_scaled']].values\n",
        "print(f'time_feat:{time_features.shape}')\n",
        "scaler_time=StandardScaler()\n",
        "normalized_time_data = scaler_time.fit_transform(time_features)\n",
        "\n",
        "X, y = create_windows(reduced_features_df, ts_normalized ,normalized_time_data, input_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybPTA92Eei4I"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN7Te5dTsQV1",
        "outputId": "53041166-c3ba-4f90-fcf9-af5229659ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(114, 6)\n"
          ]
        }
      ],
      "source": [
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "79zmkqMde7K6",
        "outputId": "35530546-8ea2-49ae-b70d-0a6d9e875278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_42 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_42               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │              \u001b[38;5;34m32\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_43 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │             \u001b[38;5;34m400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_43               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m102\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_42               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_43               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m750\u001b[0m (2.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">750</span> (2.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m702\u001b[0m (2.74 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">702</span> (2.74 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m48\u001b[0m (192.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> (192.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the TCN model\n",
        "model = Sequential()\n",
        "\n",
        "# Add Conv1D layers with padding to prevent size issues\n",
        "model.add(Conv1D(8, 3, activation='relu', padding='same', input_shape=(input_steps, 6), kernel_regularizer=l2(0.06)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Conv1D(16, 3, activation='relu', padding='same', kernel_regularizer=l2(0.06)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "# model.add(Conv1D(8, 3, activation='relu', padding='same', kernel_regularizer=l2(0.06)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.03))\n",
        "\n",
        "# Use Global Average Pooling to collapse the time dimension\n",
        "model.add(GlobalAveragePooling1D())\n",
        "\n",
        "# Dense layer for predicting the next step (output features for the next step)\n",
        "model.add(Dense(6, kernel_regularizer=l2(0.08)))  # Assuming 8 features in the output for a single step\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae', 'accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v07zQChVe9od"
      },
      "outputs": [],
      "source": [
        "\n",
        "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# history = model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "kfold = KFold(n_splits=6, shuffle=True)\n",
        "for train_idx, val_idx in kfold.split(X_train, y_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "    model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=100, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "mSEmoPCPhP65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf6e2b4-3867-47d2-f070-fa3e4a19e1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.2775 - loss: 2.8358 - mae: 0.7552 - val_accuracy: 0.1579 - val_loss: 2.6797 - val_mae: 0.7654\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3062 - loss: 2.7719 - mae: 0.7273 - val_accuracy: 0.1579 - val_loss: 2.6342 - val_mae: 0.7497\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3415 - loss: 2.7314 - mae: 0.7235 - val_accuracy: 0.1053 - val_loss: 2.5903 - val_mae: 0.7340\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2685 - loss: 2.6378 - mae: 0.6923 - val_accuracy: 0.1053 - val_loss: 2.5493 - val_mae: 0.7190\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3311 - loss: 2.4822 - mae: 0.6472 - val_accuracy: 0.1579 - val_loss: 2.5094 - val_mae: 0.7042\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3050 - loss: 2.4900 - mae: 0.6228 - val_accuracy: 0.1579 - val_loss: 2.4711 - val_mae: 0.6902\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3130 - loss: 2.3298 - mae: 0.5863 - val_accuracy: 0.2632 - val_loss: 2.4345 - val_mae: 0.6768\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2999 - loss: 2.3029 - mae: 0.5702 - val_accuracy: 0.2632 - val_loss: 2.3991 - val_mae: 0.6637\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3468 - loss: 2.3293 - mae: 0.5881 - val_accuracy: 0.3158 - val_loss: 2.3656 - val_mae: 0.6517\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3663 - loss: 2.2098 - mae: 0.5617 - val_accuracy: 0.4211 - val_loss: 2.3336 - val_mae: 0.6402\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3050 - loss: 2.1659 - mae: 0.5322 - val_accuracy: 0.5789 - val_loss: 2.3032 - val_mae: 0.6296\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4148 - loss: 2.0683 - mae: 0.4945 - val_accuracy: 0.6842 - val_loss: 2.2738 - val_mae: 0.6192\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3561 - loss: 2.1560 - mae: 0.5445 - val_accuracy: 0.6842 - val_loss: 2.2459 - val_mae: 0.6097\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3678 - loss: 2.0295 - mae: 0.4864 - val_accuracy: 0.6842 - val_loss: 2.2198 - val_mae: 0.6010\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3600 - loss: 2.0050 - mae: 0.4782 - val_accuracy: 0.6842 - val_loss: 2.1947 - val_mae: 0.5932\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3940 - loss: 1.9814 - mae: 0.4768 - val_accuracy: 0.6842 - val_loss: 2.1695 - val_mae: 0.5851\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4384 - loss: 1.9259 - mae: 0.4652 - val_accuracy: 0.6842 - val_loss: 2.1459 - val_mae: 0.5777\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3090 - loss: 1.9189 - mae: 0.4624 - val_accuracy: 0.5789 - val_loss: 2.1223 - val_mae: 0.5705\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3026 - loss: 1.8681 - mae: 0.4574 - val_accuracy: 0.5789 - val_loss: 2.0987 - val_mae: 0.5640\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3850 - loss: 1.8785 - mae: 0.4555 - val_accuracy: 0.5789 - val_loss: 2.0754 - val_mae: 0.5580\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4305 - loss: 1.7753 - mae: 0.4321 - val_accuracy: 0.5263 - val_loss: 2.0527 - val_mae: 0.5522\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3756 - loss: 1.7300 - mae: 0.4015 - val_accuracy: 0.5263 - val_loss: 2.0295 - val_mae: 0.5466\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3941 - loss: 1.7407 - mae: 0.4137 - val_accuracy: 0.5263 - val_loss: 2.0068 - val_mae: 0.5411\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3743 - loss: 1.6485 - mae: 0.3738 - val_accuracy: 0.5263 - val_loss: 1.9845 - val_mae: 0.5360\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4058 - loss: 1.6951 - mae: 0.4169 - val_accuracy: 0.5263 - val_loss: 1.9624 - val_mae: 0.5309\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4398 - loss: 1.6535 - mae: 0.3910 - val_accuracy: 0.5263 - val_loss: 1.9408 - val_mae: 0.5260\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4371 - loss: 1.5710 - mae: 0.3671 - val_accuracy: 0.5263 - val_loss: 1.9197 - val_mae: 0.5213\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3641 - loss: 1.5868 - mae: 0.3786 - val_accuracy: 0.5263 - val_loss: 1.8990 - val_mae: 0.5171\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4267 - loss: 1.5700 - mae: 0.3722 - val_accuracy: 0.5263 - val_loss: 1.8781 - val_mae: 0.5127\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4148 - loss: 1.5745 - mae: 0.3868 - val_accuracy: 0.4211 - val_loss: 1.8574 - val_mae: 0.5089\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4856 - loss: 1.5014 - mae: 0.3702 - val_accuracy: 0.4211 - val_loss: 1.8372 - val_mae: 0.5052\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3627 - loss: 1.5410 - mae: 0.3922 - val_accuracy: 0.4211 - val_loss: 1.8163 - val_mae: 0.5014\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3641 - loss: 1.4478 - mae: 0.3377 - val_accuracy: 0.4211 - val_loss: 1.7954 - val_mae: 0.4977\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3167 - loss: 1.4243 - mae: 0.3386 - val_accuracy: 0.4211 - val_loss: 1.7755 - val_mae: 0.4941\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4031 - loss: 1.4357 - mae: 0.3666 - val_accuracy: 0.4211 - val_loss: 1.7557 - val_mae: 0.4910\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3770 - loss: 1.4255 - mae: 0.3762 - val_accuracy: 0.3684 - val_loss: 1.7363 - val_mae: 0.4882\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4330 - loss: 1.3562 - mae: 0.3379 - val_accuracy: 0.4211 - val_loss: 1.7172 - val_mae: 0.4856\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4305 - loss: 1.3050 - mae: 0.3135 - val_accuracy: 0.4211 - val_loss: 1.6986 - val_mae: 0.4835\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3914 - loss: 1.3839 - mae: 0.3653 - val_accuracy: 0.3684 - val_loss: 1.6799 - val_mae: 0.4812\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4514 - loss: 1.2762 - mae: 0.3046 - val_accuracy: 0.3684 - val_loss: 1.6604 - val_mae: 0.4787\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4384 - loss: 1.2828 - mae: 0.3433 - val_accuracy: 0.3684 - val_loss: 1.6420 - val_mae: 0.4768\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4294 - loss: 1.2424 - mae: 0.3019 - val_accuracy: 0.3684 - val_loss: 1.6237 - val_mae: 0.4750\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4685 - loss: 1.2130 - mae: 0.3112 - val_accuracy: 0.3684 - val_loss: 1.6062 - val_mae: 0.4733\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4750 - loss: 1.2493 - mae: 0.3611 - val_accuracy: 0.3684 - val_loss: 1.5889 - val_mae: 0.4716\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4333 - loss: 1.1946 - mae: 0.3276 - val_accuracy: 0.3158 - val_loss: 1.5713 - val_mae: 0.4701\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4097 - loss: 1.1433 - mae: 0.2617 - val_accuracy: 0.3158 - val_loss: 1.5530 - val_mae: 0.4686\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4191 - loss: 1.1568 - mae: 0.2823 - val_accuracy: 0.3158 - val_loss: 1.5362 - val_mae: 0.4673\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4646 - loss: 1.1342 - mae: 0.3043 - val_accuracy: 0.3158 - val_loss: 1.5198 - val_mae: 0.4659\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4777 - loss: 1.0943 - mae: 0.2955 - val_accuracy: 0.3158 - val_loss: 1.5035 - val_mae: 0.4644\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4843 - loss: 1.1720 - mae: 0.3551 - val_accuracy: 0.3158 - val_loss: 1.4865 - val_mae: 0.4630\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5273 - loss: 1.0734 - mae: 0.3019 - val_accuracy: 0.3158 - val_loss: 1.4689 - val_mae: 0.4608\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4972 - loss: 1.1546 - mae: 0.3412 - val_accuracy: 0.3158 - val_loss: 1.4527 - val_mae: 0.4597\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5366 - loss: 1.0654 - mae: 0.2941 - val_accuracy: 0.3158 - val_loss: 1.4365 - val_mae: 0.4581\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4817 - loss: 0.9903 - mae: 0.2416 - val_accuracy: 0.3158 - val_loss: 1.4207 - val_mae: 0.4566\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4529 - loss: 1.0111 - mae: 0.2660 - val_accuracy: 0.3158 - val_loss: 1.4061 - val_mae: 0.4558\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4529 - loss: 1.0116 - mae: 0.3122 - val_accuracy: 0.3158 - val_loss: 1.3919 - val_mae: 0.4546\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4581 - loss: 0.9406 - mae: 0.2512 - val_accuracy: 0.3158 - val_loss: 1.3783 - val_mae: 0.4539\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4753 - loss: 0.9329 - mae: 0.2459 - val_accuracy: 0.3158 - val_loss: 1.3636 - val_mae: 0.4525\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5247 - loss: 0.9138 - mae: 0.2607 - val_accuracy: 0.3158 - val_loss: 1.3489 - val_mae: 0.4511\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4281 - loss: 0.9141 - mae: 0.2592 - val_accuracy: 0.3158 - val_loss: 1.3335 - val_mae: 0.4489\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6307 - loss: 0.9841 - mae: 0.3501 - val_accuracy: 0.3158 - val_loss: 1.3190 - val_mae: 0.4477\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4569 - loss: 0.8768 - mae: 0.2548 - val_accuracy: 0.3158 - val_loss: 1.3056 - val_mae: 0.4469\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5220 - loss: 0.8604 - mae: 0.2218 - val_accuracy: 0.3158 - val_loss: 1.2913 - val_mae: 0.4461\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4738 - loss: 0.8471 - mae: 0.2427 - val_accuracy: 0.3158 - val_loss: 1.2775 - val_mae: 0.4451\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5588 - loss: 0.8312 - mae: 0.2426 - val_accuracy: 0.3158 - val_loss: 1.2645 - val_mae: 0.4441\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5262 - loss: 0.8230 - mae: 0.2419 - val_accuracy: 0.3158 - val_loss: 1.2517 - val_mae: 0.4430\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5052 - loss: 0.8202 - mae: 0.2454 - val_accuracy: 0.3158 - val_loss: 1.2388 - val_mae: 0.4417\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5405 - loss: 0.8102 - mae: 0.2552 - val_accuracy: 0.3158 - val_loss: 1.2240 - val_mae: 0.4393\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4856 - loss: 0.7544 - mae: 0.2091 - val_accuracy: 0.3684 - val_loss: 1.2094 - val_mae: 0.4369\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5327 - loss: 0.7508 - mae: 0.2116 - val_accuracy: 0.3684 - val_loss: 1.1964 - val_mae: 0.4352\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5132 - loss: 0.7406 - mae: 0.2125 - val_accuracy: 0.3684 - val_loss: 1.1839 - val_mae: 0.4337\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5668 - loss: 0.7802 - mae: 0.2437 - val_accuracy: 0.3684 - val_loss: 1.1721 - val_mae: 0.4327\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5363 - loss: 0.7743 - mae: 0.2571 - val_accuracy: 0.3684 - val_loss: 1.1605 - val_mae: 0.4318\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5903 - loss: 0.7388 - mae: 0.2436 - val_accuracy: 0.3684 - val_loss: 1.1494 - val_mae: 0.4308\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4673 - loss: 0.7170 - mae: 0.2259 - val_accuracy: 0.3684 - val_loss: 1.1388 - val_mae: 0.4303\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5053 - loss: 0.6912 - mae: 0.2102 - val_accuracy: 0.3684 - val_loss: 1.1292 - val_mae: 0.4305\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5497 - loss: 0.6941 - mae: 0.2184 - val_accuracy: 0.3684 - val_loss: 1.1177 - val_mae: 0.4296\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5458 - loss: 0.7392 - mae: 0.2780 - val_accuracy: 0.3684 - val_loss: 1.1060 - val_mae: 0.4285\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5405 - loss: 0.6849 - mae: 0.2289 - val_accuracy: 0.4211 - val_loss: 1.0954 - val_mae: 0.4277\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5171 - loss: 0.6575 - mae: 0.2098 - val_accuracy: 0.4211 - val_loss: 1.0855 - val_mae: 0.4273\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5877 - loss: 0.6533 - mae: 0.2006 - val_accuracy: 0.4211 - val_loss: 1.0745 - val_mae: 0.4265\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5549 - loss: 0.6912 - mae: 0.2669 - val_accuracy: 0.4211 - val_loss: 1.0633 - val_mae: 0.4247\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5887 - loss: 0.6194 - mae: 0.1944 - val_accuracy: 0.4211 - val_loss: 1.0522 - val_mae: 0.4229\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6280 - loss: 0.6301 - mae: 0.2156 - val_accuracy: 0.3684 - val_loss: 1.0423 - val_mae: 0.4211\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5707 - loss: 0.6656 - mae: 0.2876 - val_accuracy: 0.3684 - val_loss: 1.0334 - val_mae: 0.4200\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5434 - loss: 0.6069 - mae: 0.2192 - val_accuracy: 0.3684 - val_loss: 1.0240 - val_mae: 0.4193\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5600 - loss: 0.5883 - mae: 0.2122 - val_accuracy: 0.3158 - val_loss: 1.0153 - val_mae: 0.4193\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6361 - loss: 0.5840 - mae: 0.2093 - val_accuracy: 0.3158 - val_loss: 1.0055 - val_mae: 0.4186\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6166 - loss: 0.5821 - mae: 0.1990 - val_accuracy: 0.3158 - val_loss: 0.9983 - val_mae: 0.4190\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5758 - loss: 0.5579 - mae: 0.1969 - val_accuracy: 0.3158 - val_loss: 0.9923 - val_mae: 0.4197\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6217 - loss: 0.5888 - mae: 0.2441 - val_accuracy: 0.3158 - val_loss: 0.9869 - val_mae: 0.4208\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5787 - loss: 0.5271 - mae: 0.1865 - val_accuracy: 0.3158 - val_loss: 0.9804 - val_mae: 0.4209\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6387 - loss: 0.5246 - mae: 0.1840 - val_accuracy: 0.3158 - val_loss: 0.9720 - val_mae: 0.4201\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5668 - loss: 0.5355 - mae: 0.1946 - val_accuracy: 0.3158 - val_loss: 0.9624 - val_mae: 0.4189\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5848 - loss: 0.5286 - mae: 0.1877 - val_accuracy: 0.3158 - val_loss: 0.9524 - val_mae: 0.4173\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6310 - loss: 0.5041 - mae: 0.1952 - val_accuracy: 0.3158 - val_loss: 0.9432 - val_mae: 0.4162\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6662 - loss: 0.5132 - mae: 0.2074 - val_accuracy: 0.3158 - val_loss: 0.9334 - val_mae: 0.4143\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7054 - loss: 0.5576 - mae: 0.2466 - val_accuracy: 0.3158 - val_loss: 0.9267 - val_mae: 0.4142\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6322 - loss: 0.5592 - mae: 0.2650 - val_accuracy: 0.3158 - val_loss: 0.9199 - val_mae: 0.4140\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6572 - loss: 0.5148 - mae: 0.2413 - val_accuracy: 0.3158 - val_loss: 0.9166 - val_mae: 0.4156\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6765 - loss: 0.5478 - mae: 0.2671 - val_accuracy: 0.5263 - val_loss: 0.7067 - val_mae: 0.3304\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6426 - loss: 0.6789 - mae: 0.3553 - val_accuracy: 0.4737 - val_loss: 0.7076 - val_mae: 0.3320\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6770 - loss: 0.5342 - mae: 0.2452 - val_accuracy: 0.4737 - val_loss: 0.7028 - val_mae: 0.3305\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6779 - loss: 0.4939 - mae: 0.2294 - val_accuracy: 0.4737 - val_loss: 0.6914 - val_mae: 0.3272\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6283 - loss: 0.4698 - mae: 0.1948 - val_accuracy: 0.4737 - val_loss: 0.6805 - val_mae: 0.3248\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6583 - loss: 0.4976 - mae: 0.2192 - val_accuracy: 0.4211 - val_loss: 0.6686 - val_mae: 0.3218\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6845 - loss: 0.4783 - mae: 0.2153 - val_accuracy: 0.4737 - val_loss: 0.6618 - val_mae: 0.3214\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7225 - loss: 0.4607 - mae: 0.2175 - val_accuracy: 0.4737 - val_loss: 0.6585 - val_mae: 0.3229\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6493 - loss: 0.5550 - mae: 0.3036 - val_accuracy: 0.4737 - val_loss: 0.6502 - val_mae: 0.3232\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6205 - loss: 0.4533 - mae: 0.2157 - val_accuracy: 0.4737 - val_loss: 0.6470 - val_mae: 0.3259\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7458 - loss: 0.4078 - mae: 0.1663 - val_accuracy: 0.4737 - val_loss: 0.6436 - val_mae: 0.3272\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6597 - loss: 0.4319 - mae: 0.1919 - val_accuracy: 0.4211 - val_loss: 0.6412 - val_mae: 0.3285\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7147 - loss: 0.4165 - mae: 0.2075 - val_accuracy: 0.4211 - val_loss: 0.6390 - val_mae: 0.3297\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6572 - loss: 0.4281 - mae: 0.2226 - val_accuracy: 0.4737 - val_loss: 0.6368 - val_mae: 0.3304\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6977 - loss: 0.4221 - mae: 0.2156 - val_accuracy: 0.4737 - val_loss: 0.6284 - val_mae: 0.3296\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6337 - loss: 0.4355 - mae: 0.2271 - val_accuracy: 0.4211 - val_loss: 0.6201 - val_mae: 0.3290\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7421 - loss: 0.3884 - mae: 0.1737 - val_accuracy: 0.4211 - val_loss: 0.6120 - val_mae: 0.3285\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6349 - loss: 0.3886 - mae: 0.1872 - val_accuracy: 0.4211 - val_loss: 0.6038 - val_mae: 0.3275\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7696 - loss: 0.3751 - mae: 0.1922 - val_accuracy: 0.4211 - val_loss: 0.5972 - val_mae: 0.3271\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6441 - loss: 0.4791 - mae: 0.2941 - val_accuracy: 0.4211 - val_loss: 0.5952 - val_mae: 0.3290\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7147 - loss: 0.3805 - mae: 0.1880 - val_accuracy: 0.4737 - val_loss: 0.5861 - val_mae: 0.3291\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6702 - loss: 0.3884 - mae: 0.2059 - val_accuracy: 0.4737 - val_loss: 0.5769 - val_mae: 0.3288\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7422 - loss: 0.3873 - mae: 0.2265 - val_accuracy: 0.5263 - val_loss: 0.5732 - val_mae: 0.3312\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7434 - loss: 0.3570 - mae: 0.1672 - val_accuracy: 0.5263 - val_loss: 0.5695 - val_mae: 0.3332\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6441 - loss: 0.3581 - mae: 0.2010 - val_accuracy: 0.5263 - val_loss: 0.5633 - val_mae: 0.3335\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6714 - loss: 0.3656 - mae: 0.1909 - val_accuracy: 0.4737 - val_loss: 0.5611 - val_mae: 0.3346\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7579 - loss: 0.3384 - mae: 0.1720 - val_accuracy: 0.4737 - val_loss: 0.5611 - val_mae: 0.3354\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8127 - loss: 0.3589 - mae: 0.2068 - val_accuracy: 0.4211 - val_loss: 0.5625 - val_mae: 0.3374\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7212 - loss: 0.3918 - mae: 0.2471 - val_accuracy: 0.4737 - val_loss: 0.5609 - val_mae: 0.3387\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6609 - loss: 0.3353 - mae: 0.1954 - val_accuracy: 0.4737 - val_loss: 0.5594 - val_mae: 0.3403\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7159 - loss: 0.3397 - mae: 0.2005 - val_accuracy: 0.4737 - val_loss: 0.5640 - val_mae: 0.3437\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6898 - loss: 0.3242 - mae: 0.1806 - val_accuracy: 0.4737 - val_loss: 0.5707 - val_mae: 0.3491\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7590 - loss: 0.3218 - mae: 0.1861 - val_accuracy: 0.4737 - val_loss: 0.5740 - val_mae: 0.3508\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7134 - loss: 0.3376 - mae: 0.1937 - val_accuracy: 0.4737 - val_loss: 0.5736 - val_mae: 0.3519\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7709 - loss: 0.3095 - mae: 0.1750 - val_accuracy: 0.4737 - val_loss: 0.5671 - val_mae: 0.3524\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7057 - loss: 0.3050 - mae: 0.1717 - val_accuracy: 0.4737 - val_loss: 0.5574 - val_mae: 0.3514\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7748 - loss: 0.2871 - mae: 0.1563 - val_accuracy: 0.4737 - val_loss: 0.5475 - val_mae: 0.3491\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7201 - loss: 0.3253 - mae: 0.2096 - val_accuracy: 0.4737 - val_loss: 0.5433 - val_mae: 0.3465\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6901 - loss: 0.2970 - mae: 0.1815 - val_accuracy: 0.4737 - val_loss: 0.5385 - val_mae: 0.3456\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7069 - loss: 0.2978 - mae: 0.1745 - val_accuracy: 0.5263 - val_loss: 0.5327 - val_mae: 0.3453\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7748 - loss: 0.2875 - mae: 0.1765 - val_accuracy: 0.5263 - val_loss: 0.5295 - val_mae: 0.3461\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7054 - loss: 0.2988 - mae: 0.1847 - val_accuracy: 0.5263 - val_loss: 0.5243 - val_mae: 0.3436\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8076 - loss: 0.2835 - mae: 0.1772 - val_accuracy: 0.5263 - val_loss: 0.5238 - val_mae: 0.3450\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8168 - loss: 0.2880 - mae: 0.1822 - val_accuracy: 0.5263 - val_loss: 0.5212 - val_mae: 0.3452\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6560 - loss: 0.2774 - mae: 0.1750 - val_accuracy: 0.5263 - val_loss: 0.5141 - val_mae: 0.3439\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7303 - loss: 0.2885 - mae: 0.1911 - val_accuracy: 0.5263 - val_loss: 0.5106 - val_mae: 0.3426\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8049 - loss: 0.2719 - mae: 0.1779 - val_accuracy: 0.5263 - val_loss: 0.5081 - val_mae: 0.3428\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7331 - loss: 0.3038 - mae: 0.2239 - val_accuracy: 0.5263 - val_loss: 0.5152 - val_mae: 0.3475\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8205 - loss: 0.2802 - mae: 0.1857 - val_accuracy: 0.5263 - val_loss: 0.5139 - val_mae: 0.3489\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7944 - loss: 0.2674 - mae: 0.1585 - val_accuracy: 0.5263 - val_loss: 0.5109 - val_mae: 0.3492\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7016 - loss: 0.2921 - mae: 0.2067 - val_accuracy: 0.5263 - val_loss: 0.5111 - val_mae: 0.3497\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7512 - loss: 0.2677 - mae: 0.2009 - val_accuracy: 0.5263 - val_loss: 0.5144 - val_mae: 0.3506\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7670 - loss: 0.2842 - mae: 0.2046 - val_accuracy: 0.5263 - val_loss: 0.5155 - val_mae: 0.3540\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8192 - loss: 0.2797 - mae: 0.2132 - val_accuracy: 0.4737 - val_loss: 0.5161 - val_mae: 0.3562\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7421 - loss: 0.2865 - mae: 0.2246 - val_accuracy: 0.4737 - val_loss: 0.5087 - val_mae: 0.3552\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7592 - loss: 0.2591 - mae: 0.1817 - val_accuracy: 0.4737 - val_loss: 0.4932 - val_mae: 0.3495\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7096 - loss: 0.2584 - mae: 0.1890 - val_accuracy: 0.5263 - val_loss: 0.4707 - val_mae: 0.3427\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6911 - loss: 0.2791 - mae: 0.2300 - val_accuracy: 0.4737 - val_loss: 0.4616 - val_mae: 0.3398\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7787 - loss: 0.2444 - mae: 0.1752 - val_accuracy: 0.4737 - val_loss: 0.4569 - val_mae: 0.3367\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7590 - loss: 0.2337 - mae: 0.1669 - val_accuracy: 0.4737 - val_loss: 0.4644 - val_mae: 0.3396\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7266 - loss: 0.2403 - mae: 0.1657 - val_accuracy: 0.4737 - val_loss: 0.4848 - val_mae: 0.3477\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6847 - loss: 0.2704 - mae: 0.2099 - val_accuracy: 0.4737 - val_loss: 0.4984 - val_mae: 0.3528\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7813 - loss: 0.2683 - mae: 0.2183 - val_accuracy: 0.4737 - val_loss: 0.4876 - val_mae: 0.3522\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8035 - loss: 0.2376 - mae: 0.1698 - val_accuracy: 0.4737 - val_loss: 0.4701 - val_mae: 0.3475\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7789 - loss: 0.2403 - mae: 0.1929 - val_accuracy: 0.4737 - val_loss: 0.4665 - val_mae: 0.3485\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8572 - loss: 0.2284 - mae: 0.1595 - val_accuracy: 0.5263 - val_loss: 0.4610 - val_mae: 0.3451\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7069 - loss: 0.3298 - mae: 0.2650 - val_accuracy: 0.4737 - val_loss: 0.4665 - val_mae: 0.3452\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7694 - loss: 0.2990 - mae: 0.2441 - val_accuracy: 0.4211 - val_loss: 0.4604 - val_mae: 0.3422\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7748 - loss: 0.2288 - mae: 0.1773 - val_accuracy: 0.4211 - val_loss: 0.4801 - val_mae: 0.3502\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6845 - loss: 0.2621 - mae: 0.1913 - val_accuracy: 0.5263 - val_loss: 0.8435 - val_mae: 0.5275\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7290 - loss: 0.2280 - mae: 0.1693 - val_accuracy: 0.5263 - val_loss: 0.8674 - val_mae: 0.5406\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7224 - loss: 0.2355 - mae: 0.1855 - val_accuracy: 0.5263 - val_loss: 0.9076 - val_mae: 0.5587\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7252 - loss: 0.2708 - mae: 0.2295 - val_accuracy: 0.5263 - val_loss: 0.9208 - val_mae: 0.5654\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6952 - loss: 0.2772 - mae: 0.2453 - val_accuracy: 0.5263 - val_loss: 0.9300 - val_mae: 0.5704\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6780 - loss: 0.2620 - mae: 0.2048 - val_accuracy: 0.5263 - val_loss: 0.8789 - val_mae: 0.5530\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7512 - loss: 0.2309 - mae: 0.1865 - val_accuracy: 0.5263 - val_loss: 0.8547 - val_mae: 0.5442\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7774 - loss: 0.2618 - mae: 0.2276 - val_accuracy: 0.5263 - val_loss: 0.8306 - val_mae: 0.5352\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6937 - loss: 0.2173 - mae: 0.1668 - val_accuracy: 0.5263 - val_loss: 0.8258 - val_mae: 0.5341\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6859 - loss: 0.2503 - mae: 0.2008 - val_accuracy: 0.5263 - val_loss: 0.8331 - val_mae: 0.5392\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7838 - loss: 0.3713 - mae: 0.3449 - val_accuracy: 0.6842 - val_loss: 0.4108 - val_mae: 0.2756\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7685 - loss: 0.2604 - mae: 0.1741 - val_accuracy: 0.6842 - val_loss: 0.4203 - val_mae: 0.2821\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7826 - loss: 0.2951 - mae: 0.2399 - val_accuracy: 0.6842 - val_loss: 0.4109 - val_mae: 0.2821\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7472 - loss: 0.3061 - mae: 0.2637 - val_accuracy: 0.6842 - val_loss: 0.3968 - val_mae: 0.2822\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7315 - loss: 0.2626 - mae: 0.2327 - val_accuracy: 0.6842 - val_loss: 0.3918 - val_mae: 0.2828\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7331 - loss: 0.2265 - mae: 0.1742 - val_accuracy: 0.6842 - val_loss: 0.3902 - val_mae: 0.2800\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7606 - loss: 0.2418 - mae: 0.1682 - val_accuracy: 0.6842 - val_loss: 0.3796 - val_mae: 0.2736\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7526 - loss: 0.2255 - mae: 0.1681 - val_accuracy: 0.6316 - val_loss: 0.3662 - val_mae: 0.2671\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7056 - loss: 0.2966 - mae: 0.2513 - val_accuracy: 0.6316 - val_loss: 0.3592 - val_mae: 0.2650\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7577 - loss: 0.2648 - mae: 0.2234 - val_accuracy: 0.6842 - val_loss: 0.3649 - val_mae: 0.2680\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7237 - loss: 0.2575 - mae: 0.2116 - val_accuracy: 0.6842 - val_loss: 0.3701 - val_mae: 0.2734\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6769 - loss: 0.2374 - mae: 0.1916 - val_accuracy: 0.6842 - val_loss: 0.3763 - val_mae: 0.2819\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7317 - loss: 0.2435 - mae: 0.2166 - val_accuracy: 0.6842 - val_loss: 0.3677 - val_mae: 0.2809\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6952 - loss: 0.2534 - mae: 0.2149 - val_accuracy: 0.6842 - val_loss: 0.3623 - val_mae: 0.2776\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7370 - loss: 0.2331 - mae: 0.1960 - val_accuracy: 0.6316 - val_loss: 0.3564 - val_mae: 0.2755\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8127 - loss: 0.2039 - mae: 0.1550 - val_accuracy: 0.6316 - val_loss: 0.3479 - val_mae: 0.2720\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6965 - loss: 0.2914 - mae: 0.2600 - val_accuracy: 0.6842 - val_loss: 0.3493 - val_mae: 0.2710\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7655 - loss: 0.2407 - mae: 0.2167 - val_accuracy: 0.6316 - val_loss: 0.3372 - val_mae: 0.2655\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7290 - loss: 0.1981 - mae: 0.1523 - val_accuracy: 0.6842 - val_loss: 0.3359 - val_mae: 0.2662\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7303 - loss: 0.2186 - mae: 0.1761 - val_accuracy: 0.6842 - val_loss: 0.3390 - val_mae: 0.2701\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7382 - loss: 0.2439 - mae: 0.2098 - val_accuracy: 0.6842 - val_loss: 0.3293 - val_mae: 0.2669\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7475 - loss: 0.2206 - mae: 0.1780 - val_accuracy: 0.6842 - val_loss: 0.3249 - val_mae: 0.2657\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7332 - loss: 0.2012 - mae: 0.1604 - val_accuracy: 0.7368 - val_loss: 0.3210 - val_mae: 0.2630\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7461 - loss: 0.2954 - mae: 0.2939 - val_accuracy: 0.7368 - val_loss: 0.3145 - val_mae: 0.2603\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7879 - loss: 0.1915 - mae: 0.1558 - val_accuracy: 0.7368 - val_loss: 0.3257 - val_mae: 0.2673\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7709 - loss: 0.1930 - mae: 0.1551 - val_accuracy: 0.7368 - val_loss: 0.3351 - val_mae: 0.2730\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7721 - loss: 0.2027 - mae: 0.1833 - val_accuracy: 0.7368 - val_loss: 0.3363 - val_mae: 0.2692\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7723 - loss: 0.1874 - mae: 0.1683 - val_accuracy: 0.7368 - val_loss: 0.3252 - val_mae: 0.2652\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7840 - loss: 0.1978 - mae: 0.1747 - val_accuracy: 0.7368 - val_loss: 0.2977 - val_mae: 0.2532\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7473 - loss: 0.2205 - mae: 0.2018 - val_accuracy: 0.7368 - val_loss: 0.2845 - val_mae: 0.2473\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7748 - loss: 0.2249 - mae: 0.1998 - val_accuracy: 0.7895 - val_loss: 0.2832 - val_mae: 0.2470\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7957 - loss: 0.1983 - mae: 0.1895 - val_accuracy: 0.8421 - val_loss: 0.2850 - val_mae: 0.2461\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7421 - loss: 0.1857 - mae: 0.1526 - val_accuracy: 0.8421 - val_loss: 0.3095 - val_mae: 0.2564\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7723 - loss: 0.1871 - mae: 0.1657 - val_accuracy: 0.8421 - val_loss: 0.3189 - val_mae: 0.2606\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7409 - loss: 0.2010 - mae: 0.2011 - val_accuracy: 0.7895 - val_loss: 0.3105 - val_mae: 0.2583\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7579 - loss: 0.1912 - mae: 0.1806 - val_accuracy: 0.7895 - val_loss: 0.2964 - val_mae: 0.2542\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7643 - loss: 0.1718 - mae: 0.1451 - val_accuracy: 0.7895 - val_loss: 0.2838 - val_mae: 0.2513\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7799 - loss: 0.2239 - mae: 0.2166 - val_accuracy: 0.8421 - val_loss: 0.2719 - val_mae: 0.2412\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7920 - loss: 0.2998 - mae: 0.2917 - val_accuracy: 0.8421 - val_loss: 0.2758 - val_mae: 0.2428\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7618 - loss: 0.2141 - mae: 0.2091 - val_accuracy: 0.8421 - val_loss: 0.2846 - val_mae: 0.2522\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7801 - loss: 0.1608 - mae: 0.1391 - val_accuracy: 0.8421 - val_loss: 0.2736 - val_mae: 0.2528\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7565 - loss: 0.2163 - mae: 0.2117 - val_accuracy: 0.8421 - val_loss: 0.2746 - val_mae: 0.2544\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7514 - loss: 0.1781 - mae: 0.1792 - val_accuracy: 0.8421 - val_loss: 0.2680 - val_mae: 0.2479\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7891 - loss: 0.1771 - mae: 0.1523 - val_accuracy: 0.8947 - val_loss: 0.2637 - val_mae: 0.2429\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7684 - loss: 0.2438 - mae: 0.2416 - val_accuracy: 0.8947 - val_loss: 0.2697 - val_mae: 0.2504\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7067 - loss: 0.2025 - mae: 0.2215 - val_accuracy: 0.8947 - val_loss: 0.2725 - val_mae: 0.2550\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7866 - loss: 0.2413 - mae: 0.2571 - val_accuracy: 0.8947 - val_loss: 0.2723 - val_mae: 0.2541\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8153 - loss: 0.2270 - mae: 0.2334 - val_accuracy: 0.9474 - val_loss: 0.2648 - val_mae: 0.2507\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7293 - loss: 0.1790 - mae: 0.1827 - val_accuracy: 0.9474 - val_loss: 0.2668 - val_mae: 0.2555\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7762 - loss: 0.2015 - mae: 0.2244 - val_accuracy: 0.8947 - val_loss: 0.2674 - val_mae: 0.2562\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7577 - loss: 0.1898 - mae: 0.1932 - val_accuracy: 0.8947 - val_loss: 0.2560 - val_mae: 0.2500\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8127 - loss: 0.1474 - mae: 0.1334 - val_accuracy: 0.8947 - val_loss: 0.2477 - val_mae: 0.2443\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8141 - loss: 0.1554 - mae: 0.1580 - val_accuracy: 0.8421 - val_loss: 0.2480 - val_mae: 0.2429\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8125 - loss: 0.1890 - mae: 0.2032 - val_accuracy: 0.8421 - val_loss: 0.2475 - val_mae: 0.2472\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8113 - loss: 0.1530 - mae: 0.1548 - val_accuracy: 0.8421 - val_loss: 0.2460 - val_mae: 0.2526\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7524 - loss: 0.1698 - mae: 0.1732 - val_accuracy: 0.8421 - val_loss: 0.2468 - val_mae: 0.2547\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7789 - loss: 0.1618 - mae: 0.1726 - val_accuracy: 0.8947 - val_loss: 0.2507 - val_mae: 0.2575\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7893 - loss: 0.1869 - mae: 0.2141 - val_accuracy: 0.8947 - val_loss: 0.2492 - val_mae: 0.2541\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7918 - loss: 0.2060 - mae: 0.2209 - val_accuracy: 0.8947 - val_loss: 0.2569 - val_mae: 0.2582\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7854 - loss: 0.1706 - mae: 0.1903 - val_accuracy: 0.8947 - val_loss: 0.2359 - val_mae: 0.2448\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7095 - loss: 0.1740 - mae: 0.1678 - val_accuracy: 0.8947 - val_loss: 0.2239 - val_mae: 0.2405\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7331 - loss: 0.1769 - mae: 0.1812 - val_accuracy: 0.8947 - val_loss: 0.2268 - val_mae: 0.2454\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7643 - loss: 0.1787 - mae: 0.1849 - val_accuracy: 0.8421 - val_loss: 0.2349 - val_mae: 0.2527\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8102 - loss: 0.1490 - mae: 0.1499 - val_accuracy: 0.8421 - val_loss: 0.2457 - val_mae: 0.2534\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7030 - loss: 0.1422 - mae: 0.1406 - val_accuracy: 0.8947 - val_loss: 0.2383 - val_mae: 0.2457\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7945 - loss: 0.1791 - mae: 0.2087 - val_accuracy: 0.8947 - val_loss: 0.2209 - val_mae: 0.2418\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7553 - loss: 0.1661 - mae: 0.1783 - val_accuracy: 0.8947 - val_loss: 0.2079 - val_mae: 0.2416\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7672 - loss: 0.2456 - mae: 0.2633 - val_accuracy: 0.8947 - val_loss: 0.2141 - val_mae: 0.2435\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8231 - loss: 0.1878 - mae: 0.2174 - val_accuracy: 0.8947 - val_loss: 0.2404 - val_mae: 0.2510\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7331 - loss: 0.1747 - mae: 0.1887 - val_accuracy: 0.8947 - val_loss: 0.2355 - val_mae: 0.2495\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7512 - loss: 0.3004 - mae: 0.3237 - val_accuracy: 0.8947 - val_loss: 0.2506 - val_mae: 0.2660\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8494 - loss: 0.1525 - mae: 0.1561 - val_accuracy: 0.8947 - val_loss: 0.2331 - val_mae: 0.2633\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8416 - loss: 0.1687 - mae: 0.1982 - val_accuracy: 0.8947 - val_loss: 0.2232 - val_mae: 0.2621\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7500 - loss: 0.1996 - mae: 0.2343 - val_accuracy: 1.0000 - val_loss: 0.2198 - val_mae: 0.2492\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7631 - loss: 0.1511 - mae: 0.1605 - val_accuracy: 0.9474 - val_loss: 0.2085 - val_mae: 0.2336\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7448 - loss: 0.1663 - mae: 0.1807 - val_accuracy: 0.8947 - val_loss: 0.1999 - val_mae: 0.2265\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8964 - loss: 0.1420 - mae: 0.1477 - val_accuracy: 0.8947 - val_loss: 0.2016 - val_mae: 0.2403\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7448 - loss: 0.1628 - mae: 0.1672 - val_accuracy: 0.8421 - val_loss: 0.2125 - val_mae: 0.2540\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6718 - loss: 0.2658 - mae: 0.3059 - val_accuracy: 0.8421 - val_loss: 0.2254 - val_mae: 0.2549\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7893 - loss: 0.1734 - mae: 0.1935 - val_accuracy: 0.8421 - val_loss: 0.2297 - val_mae: 0.2470\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7984 - loss: 0.1648 - mae: 0.1932 - val_accuracy: 0.8947 - val_loss: 0.2090 - val_mae: 0.2385\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8531 - loss: 0.1710 - mae: 0.2055 - val_accuracy: 0.8947 - val_loss: 0.1972 - val_mae: 0.2378\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7669 - loss: 0.2703 - mae: 0.3397 - val_accuracy: 0.8947 - val_loss: 0.1883 - val_mae: 0.2311\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7760 - loss: 0.1522 - mae: 0.1773 - val_accuracy: 0.8421 - val_loss: 0.1820 - val_mae: 0.2222\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7329 - loss: 0.1487 - mae: 0.1664 - val_accuracy: 0.7895 - val_loss: 0.1912 - val_mae: 0.2216\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7528 - loss: 0.1367 - mae: 0.1408 - val_accuracy: 0.7895 - val_loss: 0.1942 - val_mae: 0.2211\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7657 - loss: 0.1513 - mae: 0.1712 - val_accuracy: 0.8947 - val_loss: 0.1930 - val_mae: 0.2275\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8127 - loss: 0.1962 - mae: 0.2335 - val_accuracy: 0.8947 - val_loss: 0.1970 - val_mae: 0.2336\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7278 - loss: 0.2035 - mae: 0.2479 - val_accuracy: 0.8947 - val_loss: 0.2120 - val_mae: 0.2447\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7838 - loss: 0.1479 - mae: 0.1704 - val_accuracy: 0.8947 - val_loss: 0.2234 - val_mae: 0.2574\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7409 - loss: 0.1423 - mae: 0.1519 - val_accuracy: 0.9474 - val_loss: 0.2061 - val_mae: 0.2472\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7918 - loss: 0.1297 - mae: 0.1410 - val_accuracy: 0.9474 - val_loss: 0.1822 - val_mae: 0.2269\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8088 - loss: 0.1530 - mae: 0.1648 - val_accuracy: 0.9474 - val_loss: 0.1728 - val_mae: 0.2198\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7397 - loss: 0.2162 - mae: 0.2496 - val_accuracy: 0.8421 - val_loss: 0.1806 - val_mae: 0.2379\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7567 - loss: 0.1418 - mae: 0.1543 - val_accuracy: 0.8947 - val_loss: 0.1931 - val_mae: 0.2448\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7460 - loss: 0.1366 - mae: 0.1416 - val_accuracy: 0.8947 - val_loss: 0.2009 - val_mae: 0.2393\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7840 - loss: 0.1389 - mae: 0.1679 - val_accuracy: 0.8947 - val_loss: 0.1935 - val_mae: 0.2291\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7618 - loss: 0.1363 - mae: 0.1696 - val_accuracy: 0.8947 - val_loss: 0.1816 - val_mae: 0.2272\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7592 - loss: 0.1694 - mae: 0.2138 - val_accuracy: 0.8947 - val_loss: 0.1778 - val_mae: 0.2233\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7709 - loss: 0.1379 - mae: 0.1629 - val_accuracy: 0.8947 - val_loss: 0.1783 - val_mae: 0.2209\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8010 - loss: 0.1463 - mae: 0.1637 - val_accuracy: 0.8947 - val_loss: 0.2363 - val_mae: 0.2867\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7329 - loss: 0.1766 - mae: 0.2221 - val_accuracy: 0.9474 - val_loss: 0.2805 - val_mae: 0.3148\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7762 - loss: 0.1597 - mae: 0.2102 - val_accuracy: 0.8421 - val_loss: 0.3356 - val_mae: 0.3490\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7669 - loss: 0.1419 - mae: 0.1579 - val_accuracy: 0.8421 - val_loss: 0.3090 - val_mae: 0.3412\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8115 - loss: 0.1376 - mae: 0.1649 - val_accuracy: 0.8421 - val_loss: 0.2681 - val_mae: 0.3172\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8389 - loss: 0.1230 - mae: 0.1324 - val_accuracy: 0.8947 - val_loss: 0.2438 - val_mae: 0.2901\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8259 - loss: 0.1427 - mae: 0.1748 - val_accuracy: 0.9474 - val_loss: 0.2538 - val_mae: 0.2884\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7854 - loss: 0.1355 - mae: 0.1467 - val_accuracy: 0.8947 - val_loss: 0.2634 - val_mae: 0.2992\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7641 - loss: 0.1521 - mae: 0.1903 - val_accuracy: 0.8947 - val_loss: 0.2453 - val_mae: 0.2933\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7959 - loss: 0.1321 - mae: 0.1468 - val_accuracy: 0.9474 - val_loss: 0.2487 - val_mae: 0.3003\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7630 - loss: 0.1374 - mae: 0.1605 - val_accuracy: 0.8947 - val_loss: 0.2061 - val_mae: 0.2495\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7748 - loss: 0.1317 - mae: 0.1406 - val_accuracy: 1.0000 - val_loss: 0.2142 - val_mae: 0.2609\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7448 - loss: 0.1378 - mae: 0.1374 - val_accuracy: 1.0000 - val_loss: 0.2257 - val_mae: 0.2730\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6636 - loss: 0.1443 - mae: 0.1884 - val_accuracy: 1.0000 - val_loss: 0.2257 - val_mae: 0.2742\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7487 - loss: 0.1261 - mae: 0.1329 - val_accuracy: 0.8947 - val_loss: 0.2064 - val_mae: 0.2612\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6952 - loss: 0.1534 - mae: 0.1637 - val_accuracy: 0.8947 - val_loss: 0.1936 - val_mae: 0.2484\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7110 - loss: 0.1312 - mae: 0.1373 - val_accuracy: 0.8947 - val_loss: 0.2010 - val_mae: 0.2524\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7317 - loss: 0.1455 - mae: 0.1687 - val_accuracy: 0.9474 - val_loss: 0.2078 - val_mae: 0.2586\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7239 - loss: 0.1331 - mae: 0.1385 - val_accuracy: 0.9474 - val_loss: 0.2068 - val_mae: 0.2615\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6887 - loss: 0.1511 - mae: 0.1558 - val_accuracy: 0.8947 - val_loss: 0.2046 - val_mae: 0.2630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4GodEJ7fFG6"
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['loss'], label='Training Loss')\n",
        "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "# plt.legend()\n",
        "# # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yNqqkw1yeHL"
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB-aMaU4fU83",
        "outputId": "07962c15-2560-405a-b29e-3e198916fce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 1.2038 - mae: 0.8073\n",
            "Test Loss: [1.2037951946258545, 0.8073081970214844, 0.0]\n"
          ]
        }
      ],
      "source": [
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3FXnSGcfb3p",
        "outputId": "30043f8c-f522-43d2-c458-ae1dc5307ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "Testing MAE: 0.4052\n",
            "Testing MAE as % of Data Range: 10.25%\n",
            "Testing MSE: 0.3085\n",
            "Testing MSE as % of Data Range: 7.81%\n",
            "Testing R²: 0.5958\n"
          ]
        }
      ],
      "source": [
        "# Predict on Testing data\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Flatten the predictions and actual values\n",
        "y_test_flat = y_test.flatten()\n",
        "y_pred_test_flat = y_pred_test.flatten()\n",
        "\n",
        "# Calculate MAE and MSE\n",
        "mae_test = mean_absolute_error(y_test_flat, y_pred_test_flat)\n",
        "mse_test = mean_squared_error(y_test_flat, y_pred_test_flat)\n",
        "\n",
        "# Calculate the range of the actual data\n",
        "data_range = y_test_flat.max() - y_test_flat.min()\n",
        "\n",
        "# Convert MAE and MSE to percentage of the data range\n",
        "mae_percentage = (mae_test / data_range) * 100\n",
        "mse_percentage = (mse_test / data_range) * 100\n",
        "\n",
        "# Print the results\n",
        "print(f\"Testing MAE: {mae_test:.4f}\")\n",
        "print(f\"Testing MAE as % of Data Range: {mae_percentage:.2f}%\")\n",
        "print(f\"Testing MSE: {mse_test:.4f}\")\n",
        "print(f\"Testing MSE as % of Data Range: {mse_percentage:.2f}%\")\n",
        "\n",
        "# Optionally include R² for completeness\n",
        "r2_train = r2_score(y_test_flat, y_pred_test_flat)\n",
        "print(f\"Testing R²: {r2_train:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao8q5cjhjq1_",
        "outputId": "7ac6e2dc-f8c4-4b70-9c67-268852c21b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Training MAE: 0.2740\n",
            "Training MAE as % of Data Range: 4.04%\n",
            "Training MSE: 0.1411\n",
            "Training MSE as % of Data Range: 2.08%\n",
            "Training R²: 0.8553\n"
          ]
        }
      ],
      "source": [
        "# Predict on training data\n",
        "y_pred_train = model.predict(X_train)\n",
        "\n",
        "# Flatten the predictions and actual values\n",
        "y_train_flat = y_train.flatten()\n",
        "y_pred_train_flat = y_pred_train.flatten()\n",
        "\n",
        "# Calculate MAE and MSE\n",
        "mae_train = mean_absolute_error(y_train_flat, y_pred_train_flat)\n",
        "mse_train = mean_squared_error(y_train_flat, y_pred_train_flat)\n",
        "\n",
        "# Calculate the range of the actual data\n",
        "data_range = y_train_flat.max() - y_train_flat.min()\n",
        "\n",
        "# Convert MAE and MSE to percentage of the data range\n",
        "mae_percentage = (mae_train / data_range) * 100\n",
        "mse_percentage = (mse_train / data_range) * 100\n",
        "\n",
        "# Print the results\n",
        "print(f\"Training MAE: {mae_train:.4f}\")\n",
        "print(f\"Training MAE as % of Data Range: {mae_percentage:.2f}%\")\n",
        "print(f\"Training MSE: {mse_train:.4f}\")\n",
        "print(f\"Training MSE as % of Data Range: {mse_percentage:.2f}%\")\n",
        "\n",
        "# Optionally include R² for completeness\n",
        "r2_train = r2_score(y_train_flat, y_pred_train_flat)\n",
        "print(f\"Training R²: {r2_train:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model, '0.85_0.51_filt3_6feat.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1TyVrVB3CFZ",
        "outputId": "7b6b18a3-84c5-488f-f28d-2ecad2f08f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0.85_0.51_filt3_6feat.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHJ8LjHMclno",
        "outputId": "8bd6fe08-e179-4b30-a9e2-b2d9c15d61e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model MSE: 1.2759\n",
            "Baseline Model R2: -0.6716\n",
            "Baseline Model MAE: 0.8079\n"
          ]
        }
      ],
      "source": [
        "# Calculate the mean of each feature in the training set\n",
        "mean_baseline = np.mean(X_train[:, :, :], axis=(0, 1))  # Mean across all timesteps and windows for each feature\n",
        "\n",
        "# Use the mean of each feature as the baseline prediction for every test sample\n",
        "y_pred_baseline = np.tile(mean_baseline, (y_test.shape[0], 1))  # Repeat the mean for each test sample\n",
        "\n",
        "# Evaluate the Baseline model\n",
        "mse_baseline = mean_squared_error(y_test.flatten(), y_pred_baseline.flatten())\n",
        "mae_baseline = mean_absolute_error(y_test.flatten(), y_pred_baseline.flatten())\n",
        "r2_baseline = r2_score(y_test.flatten(), y_pred_baseline.flatten())\n",
        "\n",
        "print(f\"Baseline Model MSE: {mse_baseline:.4f}\")\n",
        "print(f\"Baseline Model R2: {r2_baseline:.4f}\")\n",
        "print(f\"Baseline Model MAE: {mae_baseline:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_new_time(year, quarter):\n",
        "  no_of_years=year-2024\n",
        "  no_of_q=((no_of_years-1)*4)+quarter\n",
        "\n",
        "  years=[]\n",
        "  quarters=[]\n",
        "\n",
        "  if no_of_years==1:\n",
        "    for i in range(no_of_q):\n",
        "      quarters.append(i+1)\n",
        "      years.append(2025)\n",
        "  else:\n",
        "     for i in range(no_of_years-1):\n",
        "      quarters.extend([1,2,3,4])\n",
        "      for j in range(4):\n",
        "        years.append(2024+i+1)\n",
        "\n",
        "      latest=years[-1]\n",
        "\n",
        "      for i in range(quarter):\n",
        "        quarters.append(i+1)\n",
        "        years.append(latest+1)\n",
        "\n",
        "  return years, quarters, len(quarters)"
      ],
      "metadata": {
        "id": "1Mb--jl_I3wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years, quarters, nstep=get_new_time(2028, 4)"
      ],
      "metadata": {
        "id": "0WRTkyVlJcMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW7DgJVNMEeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1f1d2e-749a-48dd-9661-3433dc1fc911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timesep:0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "timesep:1\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "timesep:2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "timesep:3\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "timesep:4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "timesep:5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "timesep:6\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "timesep:7\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:8\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:9\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:11\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:12\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:13\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "timesep:14\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "timesep:15\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:16\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "timesep:17\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "timesep:18\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "timesep:19\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "timesep:20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "timesep:21\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "timesep:22\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "timesep:23\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def predict_beyond_test_set(model, last_known_input, n_steps, pca, years, quarters, scaler_year ):\n",
        "    \"\"\"\n",
        "    Predicts beyond the test set by iteratively predicting the next step.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained model.\n",
        "    - last_known_input: Last known input data (shape should be (input_steps, num_input_features)).\n",
        "    - n_steps: Number of steps to predict beyond the test set.\n",
        "    - scaler: If you need to reverse scale the predictions, provide the scaler (optional).\n",
        "\n",
        "    Returns:\n",
        "    - predictions: Predicted values for the next n steps.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    current_input = last_known_input\n",
        "    time_df=pd.DataFrame({'year': years, 'quarter': quarters})\n",
        "    time_df=add_time_features(time_df, scaler_year)\n",
        "    time_features = time_df[['quarter_sin', 'quarter_cos', 'year_scaled']].values\n",
        "\n",
        "\n",
        "    for _ in range(n_steps):\n",
        "        print(f'timesep:{_}')\n",
        "\n",
        "        # Make prediction for the next step\n",
        "        if _ ==0:\n",
        "          pred = model.predict(np.expand_dims(current_input, axis=0))  # Shape (1, input_steps, num_input_features)\n",
        "\n",
        "          predictions.append(pred.flatten())  # Flatten to get a 1D prediction\n",
        "        elif _==1:\n",
        "          redundant_pred=predictions[-1]\n",
        "          pca_feat=pca.transform(redundant_pred.reshape(1, -1))\n",
        "          time=time_features[0]\n",
        "          time_reshaped = time.reshape(1, -1)  # Shape: (1, n_time_features)\n",
        "\n",
        "          # Concatenate pca_feat and time_reshaped along axis 1\n",
        "          concatenated = np.concatenate([pca_feat, time_reshaped], axis=1)\n",
        "          last_known=last_known_input[-3:]\n",
        "          final_array = np.vstack([last_known, concatenated])\n",
        "          pred=model.predict(np.expand_dims(final_array, axis=0))\n",
        "          predictions.append(pred.flatten())\n",
        "\n",
        "        elif _==2:\n",
        "          redundant_pred=predictions\n",
        "          pca_feat=pca.transform(redundant_pred)\n",
        "          time=time_features[:2]\n",
        "          # time_reshaped = time.reshape(1, -1)  # Shape: (1, n_time_features)\n",
        "\n",
        "          # # Concatenate pca_feat and time_reshaped along axis 1\n",
        "          concatenated = np.concatenate([pca_feat, time], axis=1)\n",
        "          last_known=last_known_input[-2:]\n",
        "          final_array = np.vstack([last_known, concatenated])\n",
        "          pred=model.predict(np.expand_dims(final_array, axis=0))\n",
        "          predictions.append(pred.flatten())\n",
        "        elif _==3:\n",
        "          redundant_pred=predictions\n",
        "          pca_feat=pca.transform(redundant_pred)\n",
        "          time=time_features[:3]\n",
        "          # time_reshaped = time.reshape(1, -1)  # Shape: (1, n_time_features)\n",
        "\n",
        "          # # Concatenate pca_feat and time_reshaped along axis 1\n",
        "          concatenated = np.concatenate([pca_feat, time], axis=1)\n",
        "          last_known=last_known_input[-1:]\n",
        "          final_array = np.vstack([last_known, concatenated])\n",
        "          pred=model.predict(np.expand_dims(final_array, axis=0))\n",
        "          predictions.append(pred.flatten())\n",
        "        else:\n",
        "          redundant_pred=predictions[-4:]\n",
        "          pca_feat=pca.transform(redundant_pred)\n",
        "          time=time_features[(_-3):_+1, :]\n",
        "          concatenated = np.concatenate([pca_feat, time], axis=1)\n",
        "          pred=model.predict(np.expand_dims(concatenated, axis=0))\n",
        "          predictions.append(pred.flatten())\n",
        "\n",
        "\n",
        "          # print(time_df.iloc[_])\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Example usage:\n",
        "n_steps = nstep\n",
        "\n",
        "# print(n_steps)\n",
        "\n",
        "# Assume `X_test[-1]` is the last input sequence from the test set\n",
        "last_known_input = X_test[-1]\n",
        "\n",
        "# Predict the next 20 steps\n",
        "predictions = predict_beyond_test_set(model, last_known_input, n_steps, pca, years, quarters, scaler_year)\n",
        "\n",
        "# Print the predictions\n",
        "# print(\"Predictions for the next 20 steps:\", predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unscaled_pred=scaler_ts.inverse_transform(predictions)\n",
        "\n",
        "predictions_df=pd.DataFrame({'year': years, 'quarter': quarters})\n",
        "for i, col in enumerate(targets):\n",
        "  predictions_df[col] = unscaled_pred[:, i]\n",
        "\n",
        "# print(unscaled_pred.shape)  # Check the shape of unscaled_pred\n",
        "# print(predictions_df.shape)  # Check the shape of predictions_df\n",
        "\n",
        "# predictions_df.tail()\n"
      ],
      "metadata": {
        "id": "15DZjOWnVAfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nUA3B4hTXP0j",
        "outputId": "2dd537fe-6b10-47d9-eac2-aef22632f6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year  quarter     c1_dist    c2_dist      c3_dist      c4_dist  \\\n",
              "19  2027        4  104.151260  26.049616  1040.378296  1042.276611   \n",
              "20  2028        1  109.507614  32.130676  1035.160767  1039.195435   \n",
              "21  2028        2  116.626785  41.385876  1026.501221  1034.259766   \n",
              "22  2028        3  125.237274  51.685062  1020.816101  1034.456665   \n",
              "23  2028        4  135.032623  60.943981  1020.519897  1034.253296   \n",
              "\n",
              "        c5_dist      c6_dist  \n",
              "19  2517.932373  2680.664307  \n",
              "20  2506.406250  2664.849609  \n",
              "21  2493.473145  2649.077393  \n",
              "22  2509.317139  2677.935303  \n",
              "23  2517.299561  2692.717529  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-438e7348-324b-49b3-a10f-3d499d7ca178\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>quarter</th>\n",
              "      <th>c1_dist</th>\n",
              "      <th>c2_dist</th>\n",
              "      <th>c3_dist</th>\n",
              "      <th>c4_dist</th>\n",
              "      <th>c5_dist</th>\n",
              "      <th>c6_dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2027</td>\n",
              "      <td>4</td>\n",
              "      <td>104.151260</td>\n",
              "      <td>26.049616</td>\n",
              "      <td>1040.378296</td>\n",
              "      <td>1042.276611</td>\n",
              "      <td>2517.932373</td>\n",
              "      <td>2680.664307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2028</td>\n",
              "      <td>1</td>\n",
              "      <td>109.507614</td>\n",
              "      <td>32.130676</td>\n",
              "      <td>1035.160767</td>\n",
              "      <td>1039.195435</td>\n",
              "      <td>2506.406250</td>\n",
              "      <td>2664.849609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2028</td>\n",
              "      <td>2</td>\n",
              "      <td>116.626785</td>\n",
              "      <td>41.385876</td>\n",
              "      <td>1026.501221</td>\n",
              "      <td>1034.259766</td>\n",
              "      <td>2493.473145</td>\n",
              "      <td>2649.077393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2028</td>\n",
              "      <td>3</td>\n",
              "      <td>125.237274</td>\n",
              "      <td>51.685062</td>\n",
              "      <td>1020.816101</td>\n",
              "      <td>1034.456665</td>\n",
              "      <td>2509.317139</td>\n",
              "      <td>2677.935303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2028</td>\n",
              "      <td>4</td>\n",
              "      <td>135.032623</td>\n",
              "      <td>60.943981</td>\n",
              "      <td>1020.519897</td>\n",
              "      <td>1034.253296</td>\n",
              "      <td>2517.299561</td>\n",
              "      <td>2692.717529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-438e7348-324b-49b3-a10f-3d499d7ca178')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-438e7348-324b-49b3-a10f-3d499d7ca178 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-438e7348-324b-49b3-a10f-3d499d7ca178');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00a81dd4-682d-45bd-aa1f-618975ddad69\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00a81dd4-682d-45bd-aa1f-618975ddad69')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00a81dd4-682d-45bd-aa1f-618975ddad69 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictions_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2027,\n        \"max\": 2028,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2028,\n          2027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quarter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c1_dist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          109.50761413574219,\n          135.03262329101562\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c2_dist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          32.13067626953125,\n          60.9439811706543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c3_dist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1035.1607666015625,\n          1020.5198974609375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c4_dist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1039.1954345703125,\n          1034.2532958984375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c5_dist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2506.40625,\n          2517.299560546875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c6_dist\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2664.849609375,\n          2692.717529296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW8FJP7IiB59"
      },
      "outputs": [],
      "source": [
        "# Flatten the variances from 2D to 1D\n",
        "train_variances = np.var(y_train, axis=0).flatten()  # Variance for each time series in the training set\n",
        "test_variances = np.var(y_test, axis=0).flatten()    # Variance for each time series in the test set\n",
        "\n",
        "# Check if the shapes are now 1D\n",
        "print(f\"Shape of train_variances: {train_variances.shape}\")\n",
        "print(f\"Shape of test_variances: {test_variances.shape}\")\n",
        "\n",
        "# Generate time series indices (1, 2, ..., num_features)\n",
        "time_series_indices = np.arange(1, y_train.shape[1] + 1)\n",
        "\n",
        "# Plot the variances for both y_train and y_test\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(time_series_indices - 0.2, train_variances, width=0.4, label='Train Variance', color='blue', alpha=0.7)\n",
        "plt.bar(time_series_indices + 0.2, test_variances, width=0.4, label='Test Variance', color='red', alpha=0.7)\n",
        "\n",
        "plt.xlabel('Time Series')\n",
        "plt.ylabel('Variance')\n",
        "plt.title('Variance of Time Series in Training and Test Data')\n",
        "plt.xticks(time_series_indices)  # Set x-ticks to the time series indices\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'train var; {train_variances}')\n",
        "print(f'test var; {test_variances}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1tvb9gBqn-7"
      },
      "outputs": [],
      "source": [
        "\n",
        "analyzer = innvestigate.create_analyzer(\"lrp\", model)\n",
        "\n",
        "# Sample input data (e.g., one instance from your test set)\n",
        "# X_test shape: (num_samples, input_steps, num_input_features)\n",
        "sample_input = X_test[0:1]  # Select the first test sample, shape: (1, input_steps, num_input_features)\n",
        "\n",
        "# Predict the output for the sample\n",
        "prediction = model.predict(sample_input)\n",
        "\n",
        "# Perform LRP to analyze the relevance of the input\n",
        "relevance = analyzer.analyze(sample_input)\n",
        "\n",
        "# The 'relevance' array has the same shape as the input (1, input_steps, num_input_features)\n",
        "print(\"Input shape:\", sample_input.shape)\n",
        "print(\"Relevance shape:\", relevance.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model_lstm\n",
        "model_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, activation='relu', return_sequences=True, input_shape=(4, 6)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6)  # Output layer\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model_lstm.summary()\n",
        "\n",
        "history = model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AuIdcVLUP9rl",
        "outputId": "d7509337-b7c1-4b1e-f59c-a20395ce6c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m18,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m198\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,790\u001b[0m (120.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,790</span> (120.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,790\u001b[0m (120.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,790</span> (120.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 1.0695 - mae: 0.7759 - val_loss: 1.1478 - val_mae: 0.6863\n",
            "Epoch 2/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.9612 - mae: 0.7421 - val_loss: 1.1595 - val_mae: 0.6904\n",
            "Epoch 3/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9760 - mae: 0.7492 - val_loss: 1.1695 - val_mae: 0.6928\n",
            "Epoch 4/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8460 - mae: 0.6893 - val_loss: 1.1790 - val_mae: 0.6934\n",
            "Epoch 5/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7646 - mae: 0.6571 - val_loss: 1.1869 - val_mae: 0.6923\n",
            "Epoch 6/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6913 - mae: 0.6262 - val_loss: 1.1948 - val_mae: 0.6898\n",
            "Epoch 7/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6853 - mae: 0.6251 - val_loss: 1.2030 - val_mae: 0.6857\n",
            "Epoch 8/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4787 - mae: 0.5298 - val_loss: 1.2120 - val_mae: 0.6803\n",
            "Epoch 9/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4084 - mae: 0.4865 - val_loss: 1.2211 - val_mae: 0.6746\n",
            "Epoch 10/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3884 - mae: 0.4568 - val_loss: 1.2310 - val_mae: 0.6706\n",
            "Epoch 11/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2756 - mae: 0.3753 - val_loss: 1.2443 - val_mae: 0.6721\n",
            "Epoch 12/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3198 - mae: 0.3903 - val_loss: 1.2620 - val_mae: 0.6786\n",
            "Epoch 13/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2859 - mae: 0.3700 - val_loss: 1.2787 - val_mae: 0.6853\n",
            "Epoch 14/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2261 - mae: 0.3431 - val_loss: 1.2929 - val_mae: 0.6914\n",
            "Epoch 15/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3282 - mae: 0.3965 - val_loss: 1.3035 - val_mae: 0.6961\n",
            "Epoch 16/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1959 - mae: 0.3135 - val_loss: 1.3093 - val_mae: 0.7000\n",
            "Epoch 17/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1788 - mae: 0.3055 - val_loss: 1.3051 - val_mae: 0.7011\n",
            "Epoch 18/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2327 - mae: 0.3359 - val_loss: 1.3015 - val_mae: 0.7016\n",
            "Epoch 19/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1763 - mae: 0.3030 - val_loss: 1.2926 - val_mae: 0.6984\n",
            "Epoch 20/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1912 - mae: 0.3005 - val_loss: 1.2890 - val_mae: 0.6971\n",
            "Epoch 21/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1820 - mae: 0.2984 - val_loss: 1.2863 - val_mae: 0.6955\n",
            "Epoch 22/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2009 - mae: 0.3084 - val_loss: 1.2815 - val_mae: 0.6934\n",
            "Epoch 23/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1524 - mae: 0.2605 - val_loss: 1.2797 - val_mae: 0.6933\n",
            "Epoch 24/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1815 - mae: 0.2986 - val_loss: 1.2802 - val_mae: 0.6950\n",
            "Epoch 25/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2040 - mae: 0.3096 - val_loss: 1.2680 - val_mae: 0.6938\n",
            "Epoch 26/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1805 - mae: 0.2804 - val_loss: 1.2595 - val_mae: 0.6961\n",
            "Epoch 27/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1998 - mae: 0.2946 - val_loss: 1.2532 - val_mae: 0.6960\n",
            "Epoch 28/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1964 - mae: 0.2975 - val_loss: 1.2522 - val_mae: 0.6943\n",
            "Epoch 29/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1645 - mae: 0.2740 - val_loss: 1.2580 - val_mae: 0.6937\n",
            "Epoch 30/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1328 - mae: 0.2486 - val_loss: 1.2625 - val_mae: 0.6928\n",
            "Epoch 31/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1834 - mae: 0.2813 - val_loss: 1.2544 - val_mae: 0.6877\n",
            "Epoch 32/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1418 - mae: 0.2558 - val_loss: 1.2510 - val_mae: 0.6870\n",
            "Epoch 33/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1254 - mae: 0.2490 - val_loss: 1.2507 - val_mae: 0.6884\n",
            "Epoch 34/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1226 - mae: 0.2401 - val_loss: 1.2491 - val_mae: 0.6885\n",
            "Epoch 35/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1514 - mae: 0.2535 - val_loss: 1.2458 - val_mae: 0.6891\n",
            "Epoch 36/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1459 - mae: 0.2591 - val_loss: 1.2479 - val_mae: 0.6907\n",
            "Epoch 37/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2100 - mae: 0.2861 - val_loss: 1.2509 - val_mae: 0.6911\n",
            "Epoch 38/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1589 - mae: 0.2621 - val_loss: 1.2501 - val_mae: 0.6891\n",
            "Epoch 39/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1305 - mae: 0.2393 - val_loss: 1.2514 - val_mae: 0.6887\n",
            "Epoch 40/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1929 - mae: 0.2812 - val_loss: 1.2561 - val_mae: 0.6895\n",
            "Epoch 41/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1173 - mae: 0.2351 - val_loss: 1.2590 - val_mae: 0.6899\n",
            "Epoch 42/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1028 - mae: 0.2244 - val_loss: 1.2546 - val_mae: 0.6884\n",
            "Epoch 43/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1227 - mae: 0.2341 - val_loss: 1.2461 - val_mae: 0.6873\n",
            "Epoch 44/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1259 - mae: 0.2262 - val_loss: 1.2370 - val_mae: 0.6835\n",
            "Epoch 45/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1270 - mae: 0.2395 - val_loss: 1.2287 - val_mae: 0.6780\n",
            "Epoch 46/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1274 - mae: 0.2357 - val_loss: 1.2277 - val_mae: 0.6774\n",
            "Epoch 47/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1209 - mae: 0.2312 - val_loss: 1.2326 - val_mae: 0.6803\n",
            "Epoch 48/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1114 - mae: 0.2198 - val_loss: 1.2342 - val_mae: 0.6824\n",
            "Epoch 49/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1177 - mae: 0.2295 - val_loss: 1.2300 - val_mae: 0.6806\n",
            "Epoch 50/50\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1272 - mae: 0.2391 - val_loss: 1.2255 - val_mae: 0.6775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = model_lstm.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluation Metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"R2 Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5jGQgI8Utg2",
        "outputId": "b9a9d3c9-8997-4665-a0f5-0e7a20710256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951ms/step\n",
            "MSE: 1.0831\n",
            "MAE: 0.7685\n",
            "R2 Score: -3.6281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGNiLcPnP_4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}